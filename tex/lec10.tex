\makeatletter
\def\input@path{{../}}
\makeatother
\documentclass[../main.tex]{subfiles}

\begin{document}

\begin{definition}
  Пусть $\mathcal{B}$ --- билинейная форма на $V$. Тогда говорят, что векторы $u, v \in V$ \textbf{ортогональны}($u \perp v$), если $\mathcal{B}(u, v) = 0$.
\end{definition}

\begin{remark}
  Если $\mathcal{B}$ --- симметрическая билинейная форма, то отношение ортогональности симметрично.
\end{remark}

\begin{definition}
  Базис $e_1, \dotsc, e_n$ пространства $V$ называется \textbf{ортогональным}, если $e_i \perp e_j$ при всех $i \neq j$.
\end{definition}

\begin{theorem}[Лагранжа]
  Пусть $\mathcal{B}$ --- симметрическая билинейная форма на конечномерном пространстве $V$. Тогда в $V$ существует ортогональный базис.
\end{theorem}
\begin{proof}
  Индукция по размерности. База: если $n = 1$, то любой базис ортогонален. Переход:
  \begin{enumerate}
    \item Если $\mathcal{B} = 0$, то любой базис ортогонален.
    \item Иначе существует $e_1 \in V\colon \mathcal{B}(e_1, e_1) \neq 0$. Действительно, предположим это не так. Тогда для любого $v \in V\colon q(v) = \mathbb{B}(v, v) = 0$. Но тогда заметим, что $\forall v, w \in V \colon$
    \begin{equation*}
      \mathbb{B}(v, w) = \frac{1}{2}(q(v + w) - q(v) - q(w)) = \frac{1}{2}(0 + 0 - 0) = 0
    \end{equation*}
    Таким образом получили, что $\mathbb{B} = 0$. Противоречие. Значит такой $e_1$ все же существует.

    Рассмотрим ортогональное к вектору $e_1$ подпространство. Пусть $W = \{w \in V \, | \, e_1 \perp w\}$. Очевидно $W$ это линейное подпространство. Рассмотрим следующее отображение:
    \begin{align*}
      V &\overset{\lambda}{\longrightarrow} K \\
      v &\longmapsto \mathcal{B}(v, e_1)
    \end{align*}
  Заметим, что $\Im \lambda \neq 0$, потому что $\lambda(e_1, e_1) \neq 0$. А значит $\Im \lambda = K$, потому что $K$ --- одномерное линейное пространство, а значит у него только два возможных подпространства --- $0$ и $K$. Но тогда заметим, что
  \begin{equation*}
    \dim W = \dim \Ker \lambda = \dim V - \dim \Im \lambda = n - 1
  \end{equation*}
  Тогда давайте возьмем $B' = B |_{W \times W}$ --- симметрическая билинейная форма на $W$. По индукционному предположению у $W$ существует ортогональный базис $e_2, \dotsc, e_n$. Но тогда легко видеть, что $e_1 \neq \Lin(e_2, \dotsc, e_n) = W \implies e_1, \dotsc, e_n$ --- ЛЗС. А значит $e_1, \dotsc, e_n$ --- это искомый ортогональный базис $W$.
  \end{enumerate}
\end{proof}

\begin{remark}
  $E$ --- ортогональный базис $V$ по отношению к $\mathcal{B} \iff [\mathcal{B}]_E$ диагональная.
\end{remark}

\begin{remark}
  Пусть $E = (e_1, \dotsc, e_n)$ --- ортогональный базис $V$,\; $E' = (\alpha_1 e_1, \dotsc, \alpha_n e_n),\, \alpha_i \neq 0$ и $[\mathcal{B}]_E = \diag(\lambda_1, \dotsc, \lambda_n)$. Тогда
  \begin{equation*}
    [\mathcal{B}]_{E'} = \diag(\alpha_1^2 \lambda_1, \dotsc, \alpha_n^2 \lambda_n)
  \end{equation*}
\end{remark}
\begin{proof}
  Действительно, если $E' = (\alpha_1 e_1, \dotsc, \alpha_n e_n)$ и при этом $E' = EC$, то легко можно видеть, что
  \begin{equation*}
    C = \begin{pmatrix}
      \alpha_1 & 0 & \hdots & 0 \\
      0 & \alpha_2 & \hdots & 0 \\
      \vdots & \vdots & \ddots & \vdots \\
      0 & 0 & \hdots & \alpha_n
    \end{pmatrix}
  \end{equation*}
  При этом $C$ будет обратимой так как $\alpha_i \neq 0$, а значит $C$ это искомая матрица перехода от базиса $E$ к базису $E'$. Поэтому мы можем применить формулу, полученную ранне в этом параграфе:
  \begin{equation*}
    \begin{gathered}
      [\mathcal{B}]_{E'} = C^T [\mathcal{B}]_E C
      = \\ =
      \begin{pmatrix}
        \alpha_1 & 0 & \hdots & 0 \\
        0 & \alpha_2 & \hdots & 0 \\
        \vdots & \vdots & \ddots & \vdots \\
        0 & 0 & \vdots & \alpha_n
      \end{pmatrix}^T
      \cdot
      \begin{pmatrix}
        \lambda_1 & 0 & \hdots & 0 \\
        0 & \lambda_2 & \hdots & 0 \\
        \vdots & \vdots & \ddots & \vdots \\
        0 & 0 & \vdots & \lambda_n
      \end{pmatrix}
      \cdot
      \begin{pmatrix}
        \alpha_1 & 0 & \hdots & 0 \\
        0 & \alpha_2 & \hdots & 0 \\
        \vdots & \vdots & \ddots & \vdots \\
        0 & 0 & \vdots & \alpha_n
      \end{pmatrix}
      =
      \begin{pmatrix}
        \alpha_1^2 \lambda_1 & 0 & \hdots & 0 \\
        0 & \alpha_2^2 \lambda_2 & \hdots & 0 \\
        \vdots & \vdots & \ddots & \vdots \\
        0 & 0 & \vdots & \alpha_n^2 \lambda_n
      \end{pmatrix}
      = \\ =
      \diag(\alpha_1^2 \lambda_1, \dotsc, \alpha_n^2 \lambda_n)
    \end{gathered}
  \end{equation*}
\end{proof}

\begin{theorem-non}
\label{non:8.1}
  Пусть $V$ --- конечномерное линейное пространство над полем $\C, \; \mathcal{B}$ --- симметрическая билинейная форма на $V$. Тогда существует базис $E$ пространства $V$ такой, что
  \begin{equation*}
    \hphantom{\text{ для некоторого $r$}}
    [\mathcal{B}]_E =
    \begin{pmatrix}
      E_r & 0 \\
      0 & 0
    \end{pmatrix}
    \text{ для некоторого $r$}
  \end{equation*}
  При этом $r$ --- инвариант $\mathcal{B}$.
\end{theorem-non}
\begin{proof}
  По теореме Лагранжа и замечанию к ней в $V$ существует базис $E_0$ такой, что
  \begin{equation*}
    [\mathcal{B}]_{E_0} = \diag(\lambda_1, \dotsc, \lambda_n)
  \end{equation*}
  Можно считать, что $\lambda_1, \dotsc, \lambda_r \neq 0 ; \; \lambda_{r + 1} = \dotsb = \lambda_n = 0$. Теперь заметим, что для любого $j$ $\exists \alpha_j \in \C\colon \alpha_j^2 = \lambda_j$. Пусть
  \begin{equation*}
    E = (\alpha_1^{-1} e_1, \dotsc, \alpha_r^{-1} e_r, e_{r + 1}, \dotsc, e_n)
  \end{equation*}
  Тогда
  \begin{equation*}
    [\mathcal{B}]_E = \diag
    (\underbrace{\alpha_1^{-2} \lambda_1, \dotsc, \alpha_r^{-2} \lambda_r}_{
      \mathclap{1, \dotsc, 1}
    },
    \underbrace{\lambda_{r + 1}, \dotsc, \lambda_n}_{
      \mathclap{0, \dotsc, 0}
    })
  \end{equation*}
  При этом заметим, что $r = \rk
  \begin{pmatrix}
    E_r & 0 \\
    0 & 0
  \end{pmatrix} = \rk \mathcal{B}$ --- инвариант. Поэтому и $r$ инвариант для $\mathcal{B}$.
\end{proof}

\begin{theorem}[закон инерции вещественных билинейных форм]
  Пусть $V$ --- конечномерное линейное пространство над $\R,\; \mathcal{B}$ --- симметрическая билинейная форма на $V$. Тогда существует базис $E$ такой, что
  \begin{equation*}
    [\mathcal{B}]_E = \diag(
    \underbrace{1, \dotsc, 1}_{s},
    \underbrace{-1, \dotsc, -1}_{t},
    0, \dotsc, 0)
  \end{equation*}
  При этом $s$ и $t$ --- инварианты $\mathcal{B}$.
\end{theorem}
\begin{proof}
  \begin{enumerate}
    \item Доказательство существования аналогично доказательству предложения \ref{non:8.1}. Возьмем базис $E_0$ такой, что $[\mathcal{B}]_{E_0} = \diag(\lambda_1, \dotsc, \lambda_n)$. Можно считать, что $\lambda_1, \dotsc, \lambda_r \neq 0; \; \lambda_{r + 1} = \dotsb = \lambda_n = 0$. Теперь заметим, что для любого $j\; \exists \alpha_j \in \R\colon \alpha_j^2 = |\lambda_j|$. Пусть
    \begin{equation*}
      E = (\alpha_1^{-1} e_1, \dotsc, \alpha_r^{-1} e_r, e_{r + 1}, \dotsc, e_n)
    \end{equation*}
    Тогда
    \begin{equation*}
      [\mathcal{B}]_E = \diag
      (\underbrace{\alpha_1^{-2} \lambda_1, \dotsc, \alpha_r^{-2} \lambda_r}_{
        \mathclap{\pm 1, \dotsc, \pm 1}
      },
      \underbrace{\lambda_{r + 1}, \dotsc, \lambda_n}_{
        \mathclap{0, \dotsc, 0}
      })
    \end{equation*}
    Очевидно, что среди первых $r$ координат будут встречаться лишь $\pm 1$(действительно, когда мы делим число на модуль этого же числа мы получаем $\pm 1$), а последние $n - r$ будут равны нулю. Таким образом существование доказано.
    \item Докажем, что $s$ и $t$ --- инварианты. Заметим, что
    \begin{equation*}
      \hphantom{\text{ --- инвариант $\mathcal{B}$}}
      s + t = \rk [\mathcal{B}]_E = \rk \mathcal{B}
      \text{ --- инвариант $\mathcal{B}$}
    \end{equation*}
    Таким образом осталось доказать, что $s$ --- инвариант $\mathcal{B}$(тогда и $t$ будет инвариантом как разность двух инвариантов). Предположим что это не так. Тогда существуют базисы $E_1, E_2$ такие, что
    \begin{equation*}
      \begin{gathered}
        [\mathcal{B}]_{E_1} = \diag(
        \underbrace{1, \dotsc, 1}_{s_1},
        \underbrace{-1, \dotsc, -1}_{t_1},
        0, \dotsc, 0) \\
        [\mathcal{B}]_{E_2} = \diag(
          \underbrace{1, \dotsc, 1}_{s_2},
          \underbrace{-1, \dotsc, -1}_{t_2},
          0, \dotsc, 0)
      \end{gathered}
    \end{equation*}
    И при этом $s_1 \neq s_2$. НУО можем считать что $s_1 > s_2$. Также пусть
    \begin{equation*}
      \begin{gathered}
        E_1 = (e_1, \dotsc, e_n) \\
        E_2 = (f_1, \dotsc, f_n)
      \end{gathered}
    \end{equation*}
    А так же
    \begin{equation*}
      \begin{gathered}
        U_1 = \Lin(e_1, \dotsc, e_{s_1}) \\
        U_2 = \Lin(f_{s_2 + 1}, \dotsc, f_n)
      \end{gathered}
    \end{equation*}
    Заметим, что для произвольного ненулевого $v \in U_1\colon \mathcal{B}(v, v) > 0$. Действительно,
    \begin{equation*}
      \begin{gathered}
        v = \alpha_1 e_1 + \dotsb + \alpha_{s_1} e_{s_1} \\
        \mathcal{B}(v, v) = \sum\limits_{i = 1}^{s_1} \alpha_i^2
      \end{gathered}
    \end{equation*}
    Получается такая формула, потому что функция от двух различных базисных векторов равна нулю(так как матрица Грама диагональна), и в противном случае функция от одного и того же вектора равна единице, так как индексы всех векторов не превосходят $s_1$(а значит квадратичная форма от них равна единице по определению $E_1$). При этом заметим, что $v \neq 0$, а значит $\alpha_j \neq 0$ для какого-то $j$, а значит $\mathcal{B}(v, v) > 0$.

    С другой стороны для любого $v \in U_2\colon \mathcal{B}(v, v) \leq 0$. Доказательство аналогично --- $\mathcal{B}(v, v)$ будет равна сумме какого-то количества нулей и противоположных к числам из $\R$.

    Таким образом $U_1 \cap U_2 = 0$. Но $\dim U_1 = s_1$, а $\dim U_2 = n - s_2$. Поэтому
    \begin{equation*}
      \dim U_1 + \dim U_2 = s_1 + n - s_2 > n
    \end{equation*}
    Что противоречит тому, что у этих подпространств нулевое пересечение. А значит $s$ и $t$ --- инварианты. Что и требовалось доказать.
  \end{enumerate}
\end{proof}

\begin{definition}
  Пару $(s, t)$(или просто $t$) называют \textbf{сигнатурой} билинейной формы $\mathcal{B}$.
\end{definition}

\section{Евклидовы пространства}

\begin{definition}
  Пусть $V$ --- линейное пространство над $\R$. Тогда симметрическая билинейная форма $\mathcal{B}$ на $V$ называется \textbf{положительно определенной}, если $\forall v \in V\colon \mathcal{B}(v, v) \geq 0$ и $\mathcal{B}(v, v) > 0$ при $v \neq 0$.
\end{definition}

\begin{remark}
  Аналогично определяются понятия отрицательно определенной, неположительно определенной и неотрицательно определенной билинейной формы.
\end{remark}

\begin{remark}
  Пусть $(s, t)$ --- сигнатура конечномерного пространства, $n$ --- его размерность. Тогда легко видеть, что верны следующие равносильности(самостоятельная проверка данного факта предлагается читателю в качестве упражнения):
  \begin{enumerate}
    \item Положительная определенность $\iff s = n$
    \item Отрицательная определенность $\iff t = n$
    \item Неположительная определенность $\iff s = 0$
    \item Неотрицательная определенность $\iff t = 0$
  \end{enumerate}
\end{remark}

\begin{definition}
  \textbf{Евклидовым пространством} называется линейное пространство $V$ над полем $\R$ с фиксированной положительно определенной симметрической билинейной формой $(u, v)$ --- \textbf{скалярным произведением}.
\end{definition}

\begin{definition}
  Пусть $V$ --- евклидово пространство. Тогда \textbf{длиной} или \textbf{нормой} вектора $v \in V$ называется
  \begin{equation*}
    | v | = \sqrt{(v, v)}
  \end{equation*}
\end{definition}

\begin{theorem-non}[Неравенство Коши-Буняковского]
\label{ineq:KB}
  Пусть $V$ --- евклидово пространство и $v, w \in V$. Тогда
  \begin{equation*}
    |(v, w)| \leq |v| \cdot |w|
  \end{equation*}
\end{theorem-non}
\begin{proof}
  Пусть $t \in \R$. Тогда
  \begin{equation*}
    \begin{gathered}
      0 \leq (v + tw, v + tw) =
      (v, v) + t^2 (w, w) + t((v, w) + (w, v)) =
      |w|^2 t^2 + 2 (v, w) t + |v|^2 \\
      |w|^2 t^2 + 2 (v, w) t + |v|^2 \geq 0
    \end{gathered}
  \end{equation*}
  Отсюда делаем вывод, что соответствующее квадратное уравнение имеет не больше одного корня(действительно, чтобы иметь больше одного корня парабола должна начинаться строго под осью $OX$), а значит его дискриминант неположителен. Таким образом:
  \begin{equation*}
    \begin{gathered}
      4(v, w)^2 - 4|w|^2 |v|^2 \leq 0 \\
      (v, w)^2 \leq |w|^2 \cdot |v|^2 \\
      |(v, w)| \leq |w| \cdot |v|
    \end{gathered}
  \end{equation*}
  Что и требовалось доказать.
\end{proof}

\begin{corollary*}
  Пусть $v, w \in V$. Тогда
  \begin{equation*}
    |v + w| \leq |v| + |w|
  \end{equation*}
\end{corollary*}
\begin{proof}
  Заметим, что
  \begin{equation*}
    \begin{gathered}
      | v + w |^2 = (v + w, v + w) =
      (v, v) + (w, w) + 2(v, w)
      \overset{\mathclap{
        \text{\hyperref[ineq:KB]{К-Б}}
      }}{\leq}
      |v|^2 + |w|^2 + 2 \cdot |v| \cdot |w| = (|v| + |w|)^2 \\
      | v + w |^2 \leq (|v| + |w|)^2 \\
      | v + w | \leq |v| + |w|
    \end{gathered}
  \end{equation*}
  Что и требовалось доказать.
\end{proof}

\begin{definition}
  Пусть $V$ --- евклидово пространство. \textbf{Метрикой} на $V$ называется отображение $\rho\colon V \times V \to \R_{\geq 0}$ такое, что выполняются следующие свойства:
  \begin{enumerate}
    \item $\rho(v, w) = 0 \iff v = w$
    \item $\rho(v, w) = \rho(w, v)$
    \item $\rho(u, w) \leq \rho(u, v) + \rho(v, w)$
  \end{enumerate}
\end{definition}

\begin{remark}
  $\rho(v, w) = |v - w|$ --- метрика.
\end{remark}
\begin{proof}
  \begin{enumerate}
    \item Выполняется из-за положительной определенности нашей билинейной формы.
    \item $|v - w| = \sqrt{(v - w, v - w)} = \sqrt{-1 \cdot -1 \cdot (w - v, w - v)} = |w - v|$
    \item $u - w = (u - v) + (v - w)$, а значит по следствию из неравенства К-Б: $|u - w| \leq |u - v| + |v - w|$.
  \end{enumerate}
\end{proof}

\begin{definition}
  Пусть $v, w \in V$. \textbf{Углом} между векторами $v, w$ называется $\alpha \in (0, \pi)$ такое, что
  \begin{equation*}
    (v, w) = |v| \cdot |w| \cdot \cos \alpha
  \end{equation*}
\end{definition}

\begin{remark}
  Действительно, угол всегда существует, так как по неравенству Коши-Буняковского:
  \begin{equation*}
    -1 \leq \frac{(v, w)}{|v| \cdot |w|} \leq 1
  \end{equation*}
  При этом для любого $x \in [-1, 1]$ существует единственное $\alpha \in [0, \pi]$ такое, что $\cos \alpha = x$.
\end{remark}

\begin{definition}
  Базис $E$ евклидова пространства $V$ называется \textbf{ортонормированным}, если
  $E = (e_1, \dotsc, e_n)$ и $\forall i, j\colon (e_i, e_j) = \delta_{ij}$ --- символ Кронекера($\delta_{ij} = 1$ если $i = j$, и $\delta_{ij} = 0$ иначе).
\end{definition}

\begin{theorem-non}
\label{non:8.3}
  Пусть $(f_1, \dotsc, f_n)$ --- произвольный базис $V$. Тогда существует ортонормированный базис $(e_1, \dotsc, e_n)$ такой, что $e_j \in \Lin(f_1, \dotsc, f_j) \iff \Lin(e_1, \dotsc, e_j) = \Lin(f_1, \dotsc, f_j)$
\end{theorem-non}
\begin{proof}
  Возьмем $e_1 = \frac{1}{|f_1|} f_1$. Тогда пусть $e_1, \dotsc, e_k$ уже построены и $k < n$. Давайте рассмотрим вектор вида
  \begin{equation*}
    e_{k + 1}^{\circ} = f_{k + 1} + \alpha_1 e_1 + \dotsb + \alpha_k e_k
  \end{equation*}
  Легко видеть, что такой вектор лежит в нужно нам линейной оболочке. Значит осталось подобрать такие $\alpha_j$, что наш вектор будет ортогонален всем уже взятым векторам из базиса. То есть:
  \begin{equation*}
    \begin{gathered}
      (e_{k + 1}^{\circ}, e_j) = 0 \\
      (f_{k + 1} + \alpha_1 e_1 + \dotsb + \alpha_k e_k, e_j) = 0 \\
      (f_{k + 1}, e_j) + \alpha_j \underbrace{(e_j, e_j)}_{1} + \sum\limits_{i \neq j} \alpha_i \underbrace{(e_i, e_j)}_{0} = 0\\
      (f_{k + 1}, e_j) + \alpha_j = 0 \\
      \alpha_j = -(f_{k + 1}, e_j) \cdot e_j
    \end{gathered}
  \end{equation*}
  Таким образом
  \begin{equation*}
    e_{k + 1}^{\circ} = f_{k + 1} - \sum\limits_{j = 1}^{k} (f_{k + 1}, e_j)
  \end{equation*}
  Осталось ортонормировать наш вектор, а именно пусть
  \begin{equation*}
    e_{k + 1} = \frac{1}{e_{k + 1}^{\circ}} e_{k + 1}^{\circ}
  \end{equation*}
  Легко видеть, что никакие нужные свойства от домножения на константу не поменяются, поэтому:
  \begin{equation*}
    \begin{gathered}
      (e_{k + 1}, e_1) = \dotsb = (e_{k + 1}, e_k) = 0 \\
      (e_{k + 1}, e_{k + 1}) = 1
    \end{gathered}
  \end{equation*}
  Таким образом повторяя эту операцию нужно количество раз мы получаем искомый базис. Что и требовалось доказать.
\end{proof}

\begin{remark}
  Процесс построения ортонормированного базиса, описанный в предложении \ref{non:8.3} называется \textbf{ортогонализацией Грама-Шмидта}.
\end{remark}

\end{document}
